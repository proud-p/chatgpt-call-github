{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Login: proud-p\n",
      "Repo: cta_coding_assignments\n",
      "Repo: live_code_london_website\n",
      "Repo: proud-p\n",
      "Repo: spotify-message-in-a-bottle\n",
      "Repo: spotify-roblox-project\n"
     ]
    }
   ],
   "source": [
    "# Authenticate github\n",
    "\n",
    "from github import Github\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# set directory of file to root directory\n",
    "os.chdir(\"../\")\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Replace with your GitHub personal access token\n",
    "ACCESS_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Authenticate\n",
    "g = Github(ACCESS_TOKEN)\n",
    "\n",
    "# Get user info\n",
    "user = g.get_user()\n",
    "print(\"User Login:\", user.login)\n",
    "\n",
    "# List repositories\n",
    "for repo in user.get_repos():\n",
    "    print(f\"Repo: {repo.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: system-design-primer\n",
      "URL: https://github.com/donnemartin/system-design-primer\n",
      "Stars: 277472\n",
      "----------------------------------------\n",
      "Name: awesome-python\n",
      "URL: https://github.com/vinta/awesome-python\n",
      "Stars: 225730\n",
      "----------------------------------------\n",
      "Name: project-based-learning\n",
      "URL: https://github.com/practical-tutorials/project-based-learning\n",
      "Stars: 205391\n",
      "----------------------------------------\n",
      "Name: Python\n",
      "URL: https://github.com/TheAlgorithms/Python\n",
      "Stars: 194652\n",
      "----------------------------------------\n",
      "Name: tensorflow\n",
      "URL: https://github.com/tensorflow/tensorflow\n",
      "Stars: 186540\n",
      "----------------------------------------\n",
      "Name: CS-Notes\n",
      "URL: https://github.com/CyC2018/CS-Notes\n",
      "Stars: 177435\n",
      "----------------------------------------\n",
      "Name: ohmyzsh\n",
      "URL: https://github.com/ohmyzsh/ohmyzsh\n",
      "Stars: 174203\n",
      "----------------------------------------\n",
      "Name: AutoGPT\n",
      "URL: https://github.com/Significant-Gravitas/AutoGPT\n",
      "Stars: 168650\n",
      "----------------------------------------\n",
      "Name: Python-100-Days\n",
      "URL: https://github.com/jackfrued/Python-100-Days\n",
      "Stars: 158124\n",
      "----------------------------------------\n",
      "Name: transformers\n",
      "URL: https://github.com/huggingface/transformers\n",
      "Stars: 135502\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# https://docs.github.com/en/graphql/reference/queries\n",
    "\n",
    "# GitHub API endpoint\n",
    "BASE_URL = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "# Search query\n",
    "query = \"python\"\n",
    "params = {\n",
    "    \"q\": query,  # The search query\n",
    "    \"sort\": \"stars\",  # Sort by stars\n",
    "    \"order\": \"desc\",  # Descending order\n",
    "    \"per_page\": 10,   # Number of results per page\n",
    "}\n",
    "\n",
    "# Optionally use your personal access token for authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    for repo in results[\"items\"]:\n",
    "        print(f\"Name: {repo['name']}\")\n",
    "        print(f\"URL: {repo['html_url']}\")\n",
    "        print(f\"Stars: {repo['stargazers_count']}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 422\n",
      "{'message': 'ERROR_TYPE_QUERY_PARSING_FATAL unable to parse query!', 'documentation_url': 'https://docs.github.com/rest/search/search#search-code', 'status': '422'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# get repo based on query - modified chatgpt code\n",
    " \n",
    "# uses query string\n",
    "\n",
    "# GitHub API endpoint\n",
    "BASE_URL = \"https://api.github.com/search/code\"\n",
    "\n",
    "\n",
    "# Search parameters\n",
    "query = \"touchdesigner in:readme filename:README.md\"  # Your query string\n",
    "params = {\n",
    "    \"q\": query,  # The search query\n",
    "    \"per_page\": 10,  # Number of results per page\n",
    "}\n",
    "\n",
    "# Headers with authorization\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(BASE_URL, params=params, headers=headers)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    for item in results.get(\"items\", []):\n",
    "        print(f\"File: {item['name']}\")\n",
    "        print(f\"Path: {item['path']}\")\n",
    "        print(f\"Repository: {item['repository']['full_name']}\")\n",
    "        print(f\"URL: {item['html_url']}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README Content:\n",
      "\n",
      "[![Build status](https://ci.appveyor.com/api/projects/status/github/microsoft/reporting-services-loadtest?branch=master&svg=true)](https://ci.appveyor.com/project/jtarquino/reporting-services-loadtest)\n",
      "\n",
      "# Reporting Services LoadTest\n",
      "SQL Server Reporting Services LoadTest \n",
      "\n",
      "## Synopsis\n",
      "This project contains a [Visual Studio Load Test 2015](https://www.visualstudio.com/en-us/docs/test/performance-testing/getting-started/getting-started-with-performance-testing) solution to execute synthetic load for SQL Server Reporting Services 2016, SQL Server Reporting Services 2017 and Power BI Report Server. It uses Visual Studio 2015 Enterprise but you can also run them in Visual Studio 2017 Enterprise.\n",
      "\n",
      "The usage of the project requires a good understanding of Reporting Services and the different types of items (reports, datasets, data sources, mobile reports, Power BI reports, Excel workbooks) that are available in SQL Server Reporting Services/Power BI Report Server. There is an extensive use of APIs in this project, which is not designed for typical user comsumption and can change in future versions of SQL Server Reporting Services and/or Power BI Report Server.\n",
      "\n",
      "## Build and Test\n",
      "In a Visual Studio Tools Command Prompt\n",
      "```\n",
      "c:\\repos\\Reporting-Services-LoadTest>build.cmd\n",
      "```\n",
      "Integration tests that requires a configured SQL Server Reporting Services 2016\n",
      "```\n",
      "c:\\repos\\Reporting-Services-LoadTest>Test.cmd\n",
      "```\n",
      "Integration tests that requires a configured SQL Server Reporting Services 2016 and the Data sources\n",
      "```\n",
      "c:\\repos\\Reporting-Services-LoadTest>TestContent.cmd\n",
      "```\n",
      "Included integration tests that requires a configured SQL Server Reporting Services Technical Preview with the Data sources\n",
      "```\n",
      "c:\\repos\\Reporting-Services-LoadTest>TestContentWithPBI.cmd\n",
      "```\n",
      "\n",
      "You can also build and run the tests from Visual Studio 2015, in such case ensure is using RSLoadTest.testsettings\n",
      "\n",
      "* Visual Studio Menu > Test > Test Settings > Select Test Settings File\n",
      "\n",
      "# Code of Conduct\n",
      "\n",
      "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n",
      "\n",
      "# Load Test Execution \n",
      "The tests can be executed locally or in the cloud, instructions for both are detailed below\n",
      "\n",
      "## 1. Update the Load Test Target Server Configuration\n",
      "Update the file RSTest.Common.ReportServer.dll.Config with the Reporting Services environment\n",
      "```xml\n",
      "<Configuration>\n",
      "  <ReportServerUrl>http://ssrs.westus.cloudapp.azure.com/ReportServer</ReportServerUrl>\n",
      "  <ReportPortalUrl>http://ssrs.westus.cloudapp.azure.com/Reports</ReportPortalUrl>\n",
      "  <DatasourceDatabaseServer>ssrs-datasource</DatasourceDatabaseServer>\n",
      "  <ExecutionAccount>contoso\\ProvideAUser</ExecutionAccount>\n",
      "  <ExecutionAccountPwd>ProvideAPassword</ExecutionAccountPwd>\n",
      "  <DatasourceSQLUser>ProvideASQLUser</DatasourceSQLUser>\n",
      "  <DatasourceSQLPassword>ProvideASQLPassword</DatasourceSQLPassword>\n",
      "  <ASWindowsUser>contoso\\ProvideAUser</ASWindowsUser>\n",
      "  <ASWindowsPassword>ProvideAPassword</ASWindowsPassword>\n",
      "</Configuration>\n",
      "```\n",
      "* ReportServerUrl, ReportPortalUrl should be updated to the correct location \n",
      "* ExecutionAccount and ExecutionAccountPwd should be windows users that have administrator privileges in the Reporting Services Portal\n",
      "* DatasourceSQLUser and DatasourceSQLPassword should be SQL Logins with access to the databases specified in the data sources\n",
      "* ASWindowsUser and ASWindowsPassword should be windows user that is able to connect to the Analysis Services databases specified in Power BI Reports\n",
      "\n",
      "***In order to create a SQL Server Reporting Services Load enviroment in Azure see the section Create a SSRS Load Environment in Azure*** \n",
      "\n",
      "## 2. Increase the number of MaxActiveReqForOneUser\n",
      "This setting is defined in the rsreportserver.config file in the Reporting Services Server you are testing, the tests use only one Windows user to access the server and the default value is 20, if is not modified an artificial throttling will affect the test results \n",
      "\n",
      "## 2.1 Local Run with SQL Express LocalDb\n",
      "* Open the RSLoadTest.testsettings file (double click on the file) and select \"Run tests using local computer or a test controller\"\n",
      "* Open the LoadTest to run (For example MixedLoad.loadtest)\n",
      "* Run the test\n",
      "    * In the left upper corner there is a test dropdown\n",
      "        * Select Run Load Test or Debug Load Test\n",
      "    * Make sure that you have a reasonable amount of users for a local run so you can adequately debug.\n",
      "\n",
      "## 2.2 Local Run with Load Test Results Repository Using SQL\n",
      "In case you need to store a large number of test results is recommended to use a Load Test Results Repository Using SQL \n",
      "* Create a Load Database, detailed instructions here https://msdn.microsoft.com/en-us/library/ms182600.aspx\n",
      "* Visual Studio Menu > Load Test > Manage Test Controller\n",
      "    * Controller: Select \"Local No Controller\"\n",
      "    * Load test result store: Your configured load database store from the previous step\n",
      "* Open the RSLoadTest.testsettings file (double click on the file) and select \"Run tests using local computer or a test controller\"\n",
      "* Open the LoadTest to run (For example MixedLoad.loadtest)\n",
      "* Run the test\n",
      "\n",
      "## 2.3 Cloud Run with Visual Studio Team Services\n",
      "* Open the RSLoadTest.testsettings file (double click on the file) and select \"Run Tests Using Visual Studio Team Services\"\n",
      "* Detailed instructions on https://www.visualstudio.com/en-us/docs/test/performance-testing/getting-started/getting-started-with-performance-testing , check the section ***Connect to your Visual Studio Team Services account*** for example ***https://ssrsload.visualstudio.com***\n",
      "\n",
      "### 2.3.1 Viewing Cloud Load Test Run Results\n",
      "* Open the load solution\n",
      "* Connect to your Visual Studio Team Services account (for example ***https://ssrsload.visualstudio.com***)\n",
      "* Open the Load Test Manager\n",
      "    * Load Test > Load Test Manager\n",
      "    * Double click in the result you want to see\n",
      "\n",
      "\n",
      "# Create a SQL Server Reporting Services Load Environment in Azure \n",
      "You can use the UI\n",
      "\n",
      "<a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2FReporting-Services-LoadTest%2Fmaster%2FArmTemplate%2FSSRS-MultiMachine%2Fazuredeploy.json\" target=\"_blank\">\n",
      "    <img src=\"http://azuredeploy.net/deploybutton.png\"/>\n",
      "</a>\n",
      "<a href=\"http://armviz.io/#/?load=https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2FReporting-Services-LoadTest%2Fmaster%2FArmTemplate%2FSSRS-MultiMachine%2Fazuredeploy.json\" target=\"_blank\">\n",
      "  <img src=\"http://armviz.io/visualizebutton.png\"/>\n",
      "</a>\n",
      "\n",
      "or PowerShell\n",
      "\n",
      "* Install Azure PowerShell (https://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/)\n",
      "* Edit the \\Reporting-Services-LoadTest\\ArmTemplate\\SSRS-MultiMachine\\azuredeploy.parameters.json\n",
      "    * Provide a unique ssrsDNSPrefix\n",
      "    * Provide the passwords (this user and passwords need to be used on RSTest.Common.ReportServer.dll.Config)\n",
      "    * Edit other parameter of the template such as VM Size\n",
      "* Replace 'YOUR_RESOURCE_GROUP_NAME' to a unique resource group name and then run the deployment using the following command:\n",
      "```powershell\n",
      "PS C:\\repos\\Reporting-Services-LoadTest\\ArmTemplate\\SSRS-MultiMachine\\> .\\Deploy-AzureResourceGroup.ps1 -ResourceGroupName 'YOUR_RESOURCE_GROUP_NAME' -ResourceGroupLocation 'westus2' -TemplateFile azuredeploy.json -TemplateParametersFile azuredeploy.parameters.json\n",
      "```            \n",
      "* Remote desktop into the Azure RS machine named SSRS-RS (using username and password specified in azuredeploy.parameters.json)\n",
      "* Configure SQL Server Reporting Services and ensure is running\n",
      "* In case you need to do advanced troubleshooting configure the service to take Full Dumps rsreportserver.config\n",
      "            <Add Key=\"WatsonFlags\" Value=\"0x0430\" />      \n",
      "* Increase the number of MaxActiveReqForOneUser to at least 800 in rsreportserver.config (but this really depends on your load test configuration)\n",
      "            <Add Key=\"MaxActiveReqForOneUser\" Value=\"800\" />       \n",
      "\n",
      "The deployment will take around 30 minutes. It sets up a Domain Controller, a RS Server, a SQL Server with Catalog DB and another SQL Server with a set o fdatabases that the tests uses.      \n",
      "\n",
      "\n",
      "# Tutorials\n",
      "[How to onboard a new Paginated Reports Scenario](../master/docs/OnboardPaginated.md)\n",
      "\n",
      "[How to onboard a new Mobile Reports Scenario](../master/docs/OnboardMobile.md)\n",
      "\n",
      "[How to onboard a new PowerBI Reports](../master/docs/OnboardPbi.md)\n",
      "\n",
      "# Advanced Configuration\n",
      "\n",
      "### LoadTest (.loadtest)\n",
      "The LoadTest files contains a set of scenarios that will drive the load in the system, those are standard Visual Studio Load Test files and the details of the different settings can be found on [Editing Load Test Using the Load Test Editor](https://msdn.microsoft.com/en-us/library/ff406975(v=vs.140).aspx)\n",
      "\n",
      "### Test Resources and Databases\n",
      "The Load tests deploy a set of Reports, Data sources, Mobile Reports, KPIs, Power BI Reports, and Excel Workbooks during the initialization. Most of those resources can be found under Reporting-Services-LoadTest\\src\\RSLoad\\ContentManager\\RuntimeResources. The remaining of the resources are stored at https://rsload.blob.core.windows.net/load/largefiles. Due to GitHub restriction of a file size cannot exceed 100 MB, we had to store any resource that exceeded this size in the public facing RSLoad blob.\n",
      "\n",
      "All the databases used in the tests can be found https://rsload.blob.core.windows.net/load/databases. In order to deploy them to your environment, you can run the CreateDataBase.sql script (located in that folder).\n",
      "\n",
      "### Test Execution\n",
      "The load test consists of several scenarios, which each require one or more resources. Prior to executing a scenarion, a folder will be created on the Report Server with the scenario's name. Then all the resources, required by the tests of that scenario, will be deploy on the Report Server. There will also be a set of shared data sources created in each folder. These data sources are defined in Reporting-Services-LoadTest\\src\\RSLoad\\ContentManager\\DataSources.xml.\n",
      "\n",
      "### Subscriptions, Cache Refresh Plans and Schedule Data Refreshes\n",
      "None of the load tests create subscriptions, cache refresh plans or schedule data refreshes. Historically, this was done because the underlying code involved behind subscriptions and cache refresh plans was the same as rendering a paginated report. However, starting with the introduction of Power BI Reports with embedded models, we recommend you to create Schedule Data Refreshes prior to executing a load test. To learn more on how to create a schedule data refresh, please look at our [Documentation](https://powerbi.microsoft.com/en-us/documentation/reportserver-configure-scheduled-refresh/).\n",
      "\n",
      "### Configuration Files\n",
      "* DataSources.xml : Define the datasources that will be created in the server during the test initialization (Located on Reporting-Services-LoadTest\\src\\RSLoad\\ContentManager\\DataSources.xml)\n",
      "* Paginated Reports Only \n",
      "  * ScaleReportsWeight.xml: Specifies how often a report will be used during the test execution (Located on Reporting-Services-LoadTest\\src\\RSLoad\\ContentManager\\Paginated\\ScaleReportsWeight.xml)\n",
      "  * BadCombinations.xml:  Specifies what combinatios of tests and reports shouldn't be used (Located on Reporting-Services-LoadTest\\src\\RSLoad\\ContentManager\\Paginated\\BadCombinations.xml)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "# get readme file content from query\n",
    "\n",
    "# GitHub API endpoint template\n",
    "BASE_URL = \"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n",
    "\n",
    "# Replace these with your repository details\n",
    "owner = \"microsoft\"\n",
    "repo = \"Reporting-Services-LoadTest\"\n",
    "path = \"Readme.md\"\n",
    "\n",
    "# Optionally use your personal access token for private repos or higher rate limits\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "}\n",
    "\n",
    "# Construct the URL\n",
    "url = BASE_URL.format(owner=owner, repo=repo, path=path)\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Process the response\n",
    "if response.status_code == 200:\n",
    "    file_info = response.json()\n",
    "    content_encoded = file_info.get(\"content\")\n",
    "    if content_encoded:\n",
    "        # Decode the Base64 content\n",
    "        content = base64.b64decode(content_encoded).decode(\"utf-8\")\n",
    "        print(\"README Content:\\n\")\n",
    "        print(content)\n",
    "    else:\n",
    "        print(\"README file is empty or content not found.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch README: {response.status_code}\")\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Anime4K\n",
      "Owner: bloc97\n",
      "URL: https://github.com/bloc97/Anime4K\n",
      "Description: A High-Quality Real Time Upscaler for Anime Video\n",
      "----------------------------------------\n",
      "Name: learningGLSL\n",
      "Owner: raganmd\n",
      "URL: https://github.com/raganmd/learningGLSL\n",
      "Description: None\n",
      "----------------------------------------\n",
      "Name: touchFluid\n",
      "Owner: kamindustries\n",
      "URL: https://github.com/kamindustries/touchFluid\n",
      "Description: Fluids in TouchDesigner and GLSL\n",
      "----------------------------------------\n",
      "Name: raytk\n",
      "Owner: t3kt\n",
      "URL: https://github.com/t3kt/raytk\n",
      "Description: Raymarching shader toolkit for TouchDesigner\n",
      "----------------------------------------\n",
      "Name: TD-tutorials\n",
      "Owner: exsstas\n",
      "URL: https://github.com/exsstas/TD-tutorials\n",
      "Description: All project files (including ex-Patreon only) for my TouchDesigner tutorials on Youtube\n",
      "----------------------------------------\n",
      "Name: TDNeuron\n",
      "Owner: tdneuron\n",
      "URL: https://github.com/tdneuron/TDNeuron\n",
      "Description: A deep learning framework for TouchDesigner  \n",
      "----------------------------------------\n",
      "Name: Raymarching-in-TD\n",
      "Owner: exsstas\n",
      "URL: https://github.com/exsstas/Raymarching-in-TD\n",
      "Description: GLSL raymarching within TouchDesigner\n",
      "----------------------------------------\n",
      "Name: awesome-creative-coding\n",
      "Owner: terkelg\n",
      "URL: https://github.com/terkelg/awesome-creative-coding\n",
      "Description: Creative Coding: Generative Art, Data visualization, Interaction Design, Resources.\n",
      "----------------------------------------\n",
      "Name: td-shadertoy\n",
      "Owner: matthewwachter\n",
      "URL: https://github.com/matthewwachter/td-shadertoy\n",
      "Description: None\n",
      "----------------------------------------\n",
      "Name: FlexCHOP\n",
      "Owner: vinz9\n",
      "URL: https://github.com/vinz9/FlexCHOP\n",
      "Description: NVIDIA FleX 1.2 solver integration in TouchDesigner as a CHOP\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# more complicated graphQL endpoint\n",
    "\n",
    "# GitHub GraphQL API endpoint\n",
    "GRAPHQL_URL = \"https://api.github.com/graphql\"\n",
    "\n",
    "# Replace with your GitHub personal access token\n",
    "\n",
    "\n",
    "# GraphQL query string\n",
    "query_string = \"\"\"\n",
    "{\n",
    "  search(query: \"touchdesigner glsl in:readme\", type: REPOSITORY, first: 10) {\n",
    "    edges {\n",
    "      node {\n",
    "        ... on Repository {\n",
    "          name\n",
    "          owner {\n",
    "            login\n",
    "          }\n",
    "          url\n",
    "          description\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Headers for authorization\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(\n",
    "    GRAPHQL_URL,\n",
    "    json={\"query\": query_string},\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# Process the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    for edge in data[\"data\"][\"search\"][\"edges\"]:\n",
    "        node = edge[\"node\"]\n",
    "        print(f\"Name: {node['name']}\")\n",
    "        print(f\"Owner: {node['owner']['login']}\")\n",
    "        print(f\"URL: {node['url']}\")\n",
    "        print(f\"Description: {node['description']}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
